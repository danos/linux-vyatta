From: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date: Fri, 12 Aug 2011 17:39:54 +0200
Subject: [PATCH 135/325] hrtimer: Don't call the timer handler from
 hrtimer_start
Origin: https://git.kernel.org/cgit/linux/kernel/git/rt/linux-stable-rt.git/commit?id=83a863699e8ced731f5307c66204ad6f4fbd370d

 [<ffffffff812de4a9>] __delay+0xf/0x11
 [<ffffffff812e36e9>] do_raw_spin_lock+0xd2/0x13c
 [<ffffffff815028ee>] _raw_spin_lock+0x60/0x73              rt_b->rt_runtime_lock
 [<ffffffff81068f68>] ? sched_rt_period_timer+0xad/0x281
 [<ffffffff81068f68>] sched_rt_period_timer+0xad/0x281
 [<ffffffff8109e5e1>] __run_hrtimer+0x1e4/0x347
 [<ffffffff81068ebb>] ? enqueue_rt_entity+0x36/0x36
 [<ffffffff8109f2b1>] __hrtimer_start_range_ns+0x2b5/0x40a  base->cpu_base->lock  (lock_hrtimer_base)
 [<ffffffff81068b6f>] __enqueue_rt_entity+0x26f/0x2aa       rt_b->rt_runtime_lock (start_rt_bandwidth)
 [<ffffffff81068ead>] enqueue_rt_entity+0x28/0x36
 [<ffffffff81069355>] enqueue_task_rt+0x3d/0xb0
 [<ffffffff810679d6>] enqueue_task+0x5d/0x64
 [<ffffffff810714fc>] task_setprio+0x210/0x29c              rq->lock
 [<ffffffff810b56cb>] __rt_mutex_adjust_prio+0x25/0x2a      p->pi_lock
 [<ffffffff810b5d2c>] task_blocks_on_rt_mutex+0x196/0x20f

Instead make __hrtimer_start_range_ns() return -ETIME when the timer
is in the past. Since body actually uses the hrtimer_start*() return
value its pretty safe to wreck it.

Also, it will only ever return -ETIME for timer->irqsafe || !wakeup
timers.

Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
---
 kernel/hrtimer.c | 46 ++++++++++++++++++++++------------------------
 1 file changed, 22 insertions(+), 24 deletions(-)

diff --git a/kernel/hrtimer.c b/kernel/hrtimer.c
index 90b72f9..f8b24f9 100644
--- a/kernel/hrtimer.c
+++ b/kernel/hrtimer.c
@@ -1026,30 +1026,19 @@ int __hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim,
 	 *
 	 * XXX send_remote_softirq() ?
 	 */
-	if (leftmost && new_base->cpu_base == &__get_cpu_var(hrtimer_bases)) {
+	if (leftmost && new_base->cpu_base == &__get_cpu_var(hrtimer_bases)
+		&& hrtimer_enqueue_reprogram(timer, new_base)) {
+
+		if (wakeup
 #ifdef CONFIG_PREEMPT_RT_BASE
-again:
-		if (hrtimer_enqueue_reprogram(timer, new_base)) {
-			/*
-			 * Move softirq based timers away from the rbtree in
-			 * case it expired already. Otherwise we would have a
-			 * stale base->first entry until the softirq runs.
-			 */
-			if (!hrtimer_rt_defer(timer)) {
-				ktime_t now = ktime_get();
-
-				__run_hrtimer(timer, &now);
-				/*
-				 * __run_hrtimer might have requeued timer and
-				 * it could be base->first again.
-				 */
-				if (&timer->node == base->active.next)
-					goto again;
-			}
-#else
-	if (base->cpu_base->hres_active && hrtimer_reprogram(timer, base)) {
+		    /*
+		     * Move softirq based timers away from the rbtree in
+		     * case it expired already. Otherwise we would have a
+		     * stale base->first entry until the softirq runs.
+		     */
+		    && hrtimer_rt_defer(timer)
 #endif
-		if (wakeup) {
+			) {
 			/*
 			 * We need to drop cpu_base->lock to avoid a
 			 * lock ordering issue vs. rq->lock.
@@ -1058,9 +1047,18 @@ again:
 			raise_softirq_irqoff(HRTIMER_SOFTIRQ);
 			local_irq_restore(flags);
 			return ret;
-		} else {
-			__raise_softirq_irqoff(HRTIMER_SOFTIRQ);
 		}
+
+		/*
+		 * In case we failed to reprogram the timer (mostly
+		 * because out current timer is already elapsed),
+		 * remove it again and report a failure. This avoids
+		 * stale base->first entries.
+		 */
+		debug_deactivate(timer);
+		__remove_hrtimer(timer, new_base,
+				 timer->state & HRTIMER_STATE_CALLBACK, 0);
+		ret = -ETIME;
 	}
 
 	unlock_hrtimer_base(timer, &flags);
